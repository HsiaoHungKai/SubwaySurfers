{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b2ee5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from Segnet import SegNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cce0f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_predictions(\n",
    "    model: torch.nn.Module,\n",
    "    data: list,\n",
    "    device: torch.device = \"cpu\"\n",
    "):\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    with torch.inference_mode():\n",
    "        for sample in data:\n",
    "            sample = torch.unsqueeze(sample, dim=0).to(device)\n",
    "            pred = model(sample)\n",
    "            pred = pred.squeeze()\n",
    "            predictions.append(pred)\n",
    "\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb349fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "checkpoint = torch.load('best_depth_model.pth', weights_only=False)\n",
    "model = SegNet(\n",
    "    in_channels=3,\n",
    "    out_channels=1,\n",
    "    features=checkpoint['config']['features']\n",
    ")\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "print(f\"features: {checkpoint['config']['features']}\\nlearning rate: {checkpoint['config']['lr']}\\nbatch size: {checkpoint['config']['batch_size']}\\nloss: {checkpoint['test_loss']}\")\n",
    "\n",
    "_, _, testset = torch.utils.data.random_split(dataset, [0.7, 0.15, 0.15])\n",
    "samples = random.sample(range(len(testset)), 5)\n",
    "predictions = make_predictions(model, [testset[i][0] for i in samples], device=device)\n",
    "\n",
    "# Show original image, ground truth depth, and predicted depth\n",
    "fig, axes = plt.subplots(3, 5, figsize=(15, 9))\n",
    "\n",
    "for i, idx in enumerate(samples):\n",
    "    image, depth_map = testset[idx]\n",
    "    pred = predictions[i].cpu().numpy()\n",
    "\n",
    "    # Convert tensors back to numpy for plotting\n",
    "    if isinstance(image, torch.Tensor):\n",
    "        image = image.permute(1, 2, 0).numpy()\n",
    "    if isinstance(depth_map, torch.Tensor):\n",
    "        depth_map = depth_map.numpy().squeeze()\n",
    "\n",
    "    # Row 1: Original images\n",
    "    axes[0, i].imshow(image)\n",
    "    axes[0, i].set_title(f'Image {idx}')\n",
    "    axes[0, i].axis('off')\n",
    "\n",
    "    # Row 2: Ground truth depth maps\n",
    "    axes[1, i].imshow(depth_map, cmap='gray')\n",
    "    axes[1, i].set_title(f'Ground Truth {idx}')\n",
    "    axes[1, i].axis('off')\n",
    "\n",
    "    # Row 3: Predicted depth maps\n",
    "    axes[2, i].imshow(pred, cmap='gray')\n",
    "    axes[2, i].set_title(f'Predicted {idx}')\n",
    "    axes[2, i].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
