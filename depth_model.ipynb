{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a009e0d",
   "metadata": {},
   "source": [
    "### Goal\n",
    "- Input: RGB image.\n",
    "- Teacher: Depth Anything V2 → predicts a high-quality depth map.\n",
    "- Student: A smaller, faster model → learns to mimic the teacher’s depth map predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ed9a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "import torchvision\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm.auto import tqdm\n",
    "from timeit import default_timer as timer\n",
    "import random\n",
    "\n",
    "from SegNet import SegNet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "815c000f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for google colab\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "\n",
    "# !unzip /content/drive/MyDrive/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf102b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DepthDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, images_dir, depth_maps_dir, transform=None):\n",
    "        self.images_dir = images_dir\n",
    "        self.depth_maps_dir = depth_maps_dir\n",
    "        self.transform = transform\n",
    "        \n",
    "        self.files = [f for f in os.listdir(images_dir) if f.lower().endswith('.png')]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image_path = os.path.join(self.images_dir, self.files[idx])\n",
    "        depth_map_path = os.path.join(self.depth_maps_dir, self.files[idx])\n",
    "        \n",
    "        image = plt.imread(image_path)\n",
    "        depth_map = plt.imread(depth_map_path)[:,:,0]\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            depth_map = self.transform(depth_map)\n",
    "\n",
    "        return image, depth_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a2945e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = DepthDataset(\n",
    "    images_dir='data/depth_data/images',\n",
    "    depth_maps_dir='data/depth_data/depth_maps',\n",
    "    transform=ToTensor(),\n",
    ")\n",
    "print(dataset.__len__(), \"images and depth maps found in dataset.\")\n",
    "\n",
    "# Create a figure with 2 rows and 5 columns\n",
    "fig, axes = plt.subplots(2, 5, figsize=(15, 6))\n",
    "\n",
    "# Get 5 random samples from the dataset\n",
    "indices = np.random.choice(len(dataset), 5, replace=False)\n",
    "\n",
    "for i, idx in enumerate(indices):\n",
    "    # Get image and depth map\n",
    "    image, depth_map = dataset[idx]\n",
    "    \n",
    "    # Convert tensors back to numpy for plotting\n",
    "    if isinstance(image, torch.Tensor):\n",
    "        image = image.permute(1, 2, 0).numpy()\n",
    "    if isinstance(depth_map, torch.Tensor):\n",
    "        depth_map = depth_map.numpy().squeeze()\n",
    "    \n",
    "    # Plot RGB image in first row\n",
    "    axes[0, i].imshow(image)\n",
    "    axes[0, i].set_title(f'Image {idx}')\n",
    "    axes[0, i].axis('off')\n",
    "    \n",
    "    # Plot depth map in second row\n",
    "    axes[1, i].imshow(depth_map, cmap='gray')\n",
    "    axes[1, i].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "746ec29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "train, val, test = torch.utils.data.random_split(dataset, [0.7, 0.15, 0.15])\n",
    "train.__len__(), val.__len__(), test.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba1b1fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train, batch_size=32, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val, batch_size=32, shuffle=False)\n",
    "test_loader = torch.utils.data.DataLoader(test, batch_size=32, shuffle=False)\n",
    "\n",
    "images, depth_maps = next(iter(train_loader))\n",
    "print(f'Batch of images shape: {images.shape}')\n",
    "print(f'Batch of depth maps shape: {depth_maps.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f50b69a7",
   "metadata": {},
   "source": [
    "Sorce: https://arxiv.org/pdf/1406.2283"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9087ee99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'mps' if torch.backends.mps.is_available() else 'cpu')\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = SegNet(in_channels=3, out_channels=1).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6512c379",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace CrossEntropyLoss with MSELoss for depth estimation\n",
    "loss_fn = nn.MSELoss()  # Use MSE for regression tasks\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10cddc59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix the training loop - pass both prediction and target to loss function\n",
    "torch.manual_seed(42)  \n",
    "train_time_start_on_cpu = timer()\n",
    "\n",
    "epochs = 3\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    print(f'Epoch: {epoch + 1} \\n------------')\n",
    "    # Training loop\n",
    "    train_loss = 0.0\n",
    "    for batch, (X, y) in enumerate(train_loader):\n",
    "        # Move data to device and ensure float32\n",
    "        X = X.to(device).float()\n",
    "        y = y.to(device).float()\n",
    "        \n",
    "        model.train()\n",
    "        y_pred = model(X)\n",
    "        \n",
    "        # Fix: Pass both prediction and target to loss function\n",
    "        loss = loss_fn(y_pred, y) \n",
    "        train_loss += loss.item()  # Use .item() to get scalar value\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch % 40 == 0:\n",
    "            print(f'Loss: {loss.item():.5f} | Batch: {batch + 1}/{len(train_loader)}')\n",
    "       \n",
    "    train_loss /= len(train_loader) \n",
    "    \n",
    "    # Testing loop\n",
    "    test_loss, test_acc = 0.0, 0.0\n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        for X_test, y_test in test_loader:\n",
    "            # Move test data to device\n",
    "            X_test = X_test.to(device).float()\n",
    "            y_test = y_test.to(device).float()\n",
    "            \n",
    "            y_pred = model(X_test)\n",
    "            loss = loss_fn(y_pred, y_test)  # Fix: Pass both arguments\n",
    "            test_loss += loss.item()  # Use .item() here too\n",
    "            test_acc += (y_pred.squeeze() - y_test).abs().mean().item()\n",
    "\n",
    "        test_loss /= len(test_loader)\n",
    "        test_acc /= len(test_loader)\n",
    "        \n",
    "    print(f'Train Loss: {train_loss:.5f} | Test Loss: {test_loss:.5f} | Test MAE: {test_acc:.5f}')\n",
    "    print('-----------------------------------')\n",
    "    \n",
    "train_time_end_on_cpu = timer()\n",
    "total_train_time = train_time_end_on_cpu - train_time_start_on_cpu\n",
    "print(f'Total training time: {total_train_time:.2f} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f5aad91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(model.state_dict(), 'model_weights.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f87563",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = SegNet(in_channels=3, out_channels=1).to(device)\n",
    "# model.load_state_dict(torch.load('model_weights.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "699c4c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_predictions(\n",
    "    model: torch.nn.Module,\n",
    "    data: list,\n",
    "    device=device\n",
    "):\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    with torch.inference_mode():\n",
    "        for sample in data:\n",
    "            sample = torch.unsqueeze(sample, dim=0).to(device)\n",
    "            pred = model(sample)\n",
    "            pred = pred.squeeze()\n",
    "            predictions.append(pred)\n",
    "            \n",
    "    return predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe321e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = random.sample(range(len(test)), 5)\n",
    "predictions = make_predictions(model, [test[i][0] for i in samples])\n",
    "\n",
    "# Show original image, ground truth depth, and predicted depth\n",
    "fig, axes = plt.subplots(3, 5, figsize=(15, 9))\n",
    "\n",
    "for i, idx in enumerate(samples):           \n",
    "    image, depth_map = test[idx]\n",
    "    pred = predictions[i].cpu().numpy()\n",
    "    \n",
    "    # Convert tensors back to numpy for plotting\n",
    "    if isinstance(image, torch.Tensor):\n",
    "        image = image.permute(1, 2, 0).numpy()\n",
    "    if isinstance(depth_map, torch.Tensor):\n",
    "        depth_map = depth_map.numpy().squeeze()\n",
    "    \n",
    "    # Row 1: Original images\n",
    "    axes[0, i].imshow(image)\n",
    "    axes[0, i].set_title(f'Image {idx}')\n",
    "    axes[0, i].axis('off')\n",
    "    \n",
    "    # Row 2: Ground truth depth maps\n",
    "    axes[1, i].imshow(depth_map, cmap='gray')\n",
    "    axes[1, i].set_title(f'Ground Truth {idx}')\n",
    "    axes[1, i].axis('off')\n",
    "    \n",
    "    # Row 3: Predicted depth maps\n",
    "    axes[2, i].imshow(pred, cmap='gray')\n",
    "    axes[2, i].set_title(f'Predicted {idx}')\n",
    "    axes[2, i].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
